{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_schema = StructType([StructField(\"IncidentName\",IntegerType(),True),\n",
    "                          StructField(\"Category\",StringType(),True),\n",
    "                          StructField(\"Descript\",StringType(),True),\n",
    "                          StructField(\"DayofWeek\",StringType(),True),\n",
    "                          StructField(\"Date\",StringType(),True),\n",
    "                          StructField(\"Time\",StringType(),True),\n",
    "                          StructField(\"PdDistrict\",StringType(),True),\n",
    "                          StructField(\"Resolution\",StringType(),True),\n",
    "                          StructField(\"Address\",StringType(),True),\n",
    "                          StructField(\"X\",DoubleType(),True),\n",
    "                          StructField(\"Y\",DoubleType(),True),\n",
    "                          StructField(\"Location\",StringType(),True),\n",
    "                          StructField(\"PdID\",StringType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "crimeDF = spark.read.csv('s3a://crimedatafyp/crimeData/Sample9.csv',header=True,schema=crime_schema)\n",
    "crimeDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IncidentName: integer (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Descript: string (nullable = true)\n",
      " |-- DayofWeek: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      " |-- Resolution: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- X: double (nullable = true)\n",
      " |-- Y: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- PdID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crimeDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Category: string (nullable = true)\n",
      " |-- DayofWeek: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropList = [\"IncidentName\",\"Descript\",\"Resolution\",\"Address\",\"Location\",\"PdID\",\"X\",\"Y\"]\n",
    "crimeDF = crimeDF.select([column for column in crimeDF.columns if column not in dropList])\n",
    "crimeDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+----------+-----+----------+----+-----+---+----+\n",
      "|      Category|DayofWeek|      Date| Time|PdDistrict|Year|Month|Day|Hour|\n",
      "+--------------+---------+----------+-----+----------+----+-----+---+----+\n",
      "|     VANDALISM|   Friday|08/04/2006|01:00|   TARAVAL|2006|    8|  4|   1|\n",
      "|       ASSAULT|  Tuesday|05/25/2004|16:30|      PARK|2004|    5| 25|  16|\n",
      "|OTHER OFFENSES|Wednesday|09/10/2003|18:20|   BAYVIEW|2003|    9| 10|  18|\n",
      "| LARCENY/THEFT|   Monday|11/23/2009|04:00|   TARAVAL|2009|   11| 23|   4|\n",
      "| LARCENY/THEFT|  Tuesday|06/28/2011|04:47|  NORTHERN|2011|    6| 28|   4|\n",
      "| LARCENY/THEFT|Wednesday|11/03/2004|13:45|  SOUTHERN|2004|   11|  3|  13|\n",
      "| VEHICLE THEFT|Wednesday|06/09/2010|12:55|   MISSION|2010|    6|  9|  12|\n",
      "| DRUG/NARCOTIC| Thursday|04/14/2011|08:15| INGLESIDE|2011|    4| 14|   8|\n",
      "|  NON-CRIMINAL| Saturday|12/04/2004|10:00|   CENTRAL|2004|   12|  4|  10|\n",
      "| LARCENY/THEFT| Saturday|01/22/2005|17:00|  SOUTHERN|2005|    1| 22|  17|\n",
      "|       RUNAWAY|   Monday|04/01/2013|11:30|   TARAVAL|2013|    4|  1|  11|\n",
      "|OTHER OFFENSES|   Sunday|07/16/2006|12:02|  RICHMOND|2006|    7| 16|  12|\n",
      "|       ASSAULT|   Monday|06/10/2013|21:56|  RICHMOND|2013|    6| 10|  21|\n",
      "| DRUG/NARCOTIC|  Tuesday|09/05/2006|23:59|TENDERLOIN|2006|    9|  5|  23|\n",
      "|     VANDALISM|   Friday|06/20/2003|00:35|  NORTHERN|2003|    6| 20|   0|\n",
      "|OTHER OFFENSES|   Monday|04/06/2009|11:20|  SOUTHERN|2009|    4|  6|  11|\n",
      "| VEHICLE THEFT| Thursday|06/12/2008|07:30| INGLESIDE|2008|    6| 12|   7|\n",
      "| LARCENY/THEFT|   Monday|12/26/2011|16:13|   MISSION|2011|   12| 26|  16|\n",
      "| VEHICLE THEFT| Saturday|03/29/2008|20:00|   MISSION|2008|    3| 29|  20|\n",
      "|   DRUNKENNESS| Thursday|12/15/2005|23:47|  SOUTHERN|2005|   12| 15|  23|\n",
      "+--------------+---------+----------+-----+----------+----+-----+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "crimeNewDF = crimeDF.withColumn('Year',year(unix_timestamp('Date', 'MM/dd/yyyy').cast(\"timestamp\")))\\\n",
    "                    .withColumn('Month',month(unix_timestamp('Date', 'MM/dd/yyyy').cast(\"timestamp\")))\\\n",
    "                    .withColumn('Day',dayofmonth(unix_timestamp('Date', 'MM/dd/yyyy').cast(\"timestamp\")))\\\n",
    "                    .withColumn('Hour',hour('Time'))\n",
    "crimeNewDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+----------+----+-----+---+----+\n",
      "|      Category|DayofWeek|PdDistrict|Year|Month|Day|Hour|\n",
      "+--------------+---------+----------+----+-----+---+----+\n",
      "|     VANDALISM|   Friday|   TARAVAL|2006|    8|  4|   1|\n",
      "|       ASSAULT|  Tuesday|      PARK|2004|    5| 25|  16|\n",
      "|OTHER OFFENSES|Wednesday|   BAYVIEW|2003|    9| 10|  18|\n",
      "| LARCENY/THEFT|   Monday|   TARAVAL|2009|   11| 23|   4|\n",
      "| LARCENY/THEFT|  Tuesday|  NORTHERN|2011|    6| 28|   4|\n",
      "| LARCENY/THEFT|Wednesday|  SOUTHERN|2004|   11|  3|  13|\n",
      "| VEHICLE THEFT|Wednesday|   MISSION|2010|    6|  9|  12|\n",
      "| DRUG/NARCOTIC| Thursday| INGLESIDE|2011|    4| 14|   8|\n",
      "|  NON-CRIMINAL| Saturday|   CENTRAL|2004|   12|  4|  10|\n",
      "| LARCENY/THEFT| Saturday|  SOUTHERN|2005|    1| 22|  17|\n",
      "|       RUNAWAY|   Monday|   TARAVAL|2013|    4|  1|  11|\n",
      "|OTHER OFFENSES|   Sunday|  RICHMOND|2006|    7| 16|  12|\n",
      "|       ASSAULT|   Monday|  RICHMOND|2013|    6| 10|  21|\n",
      "| DRUG/NARCOTIC|  Tuesday|TENDERLOIN|2006|    9|  5|  23|\n",
      "|     VANDALISM|   Friday|  NORTHERN|2003|    6| 20|   0|\n",
      "|OTHER OFFENSES|   Monday|  SOUTHERN|2009|    4|  6|  11|\n",
      "| VEHICLE THEFT| Thursday| INGLESIDE|2008|    6| 12|   7|\n",
      "| LARCENY/THEFT|   Monday|   MISSION|2011|   12| 26|  16|\n",
      "| VEHICLE THEFT| Saturday|   MISSION|2008|    3| 29|  20|\n",
      "|   DRUNKENNESS| Thursday|  SOUTHERN|2005|   12| 15|  23|\n",
      "+--------------+---------+----------+----+-----+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crimeNewDF=crimeNewDF.drop('Date').drop('Time').drop('X').drop('Y')\n",
    "crimeNewDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  categorical features\n",
      "3  numerical features\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [item[0] for item in crimeNewDF.dtypes if item[1].startswith('string')] \n",
    "print(str(len(cat_cols)) + '  categorical features')\n",
    "num_cols = [item[0] for item in crimeNewDF.dtypes if item[1].startswith('int') | item[1].startswith('double')][1:]\n",
    "print(str(len(num_cols)) + '  numerical features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index crime category\n",
    "from pyspark.ml.feature import StringIndexer,IndexToString\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "(trainingData,testData) = crimeNewDF.randomSplit([0.7,0.3],seed= 100)\n",
    "\n",
    "catIndexer = StringIndexer(inputCol=\"Category\",outputCol=\"label\",handleInvalid='keep')\n",
    "\n",
    "indexers = [StringIndexer(inputCol= column, outputCol=column+\"_index\") for column in list(set(crimeNewDF.columns)-set(['Year','Month','Day','Hour','Category']))]\n",
    "\n",
    "encoders = [OneHotEncoderEstimator(\n",
    "    inputCols=[indexer.getOutputCol()],\n",
    "    outputCols=[indexer.getOutputCol()+\"_encoded\"]) for indexer in indexers]\n",
    "\n",
    "assemblerInputs = [column + \"_index_encoded\" for column in list(set(crimeNewDF.columns)-set(['Year','Month','Day','Hour','Category']))] + num_cols\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "            inputCols=assemblerInputs,\n",
    "            outputCol=\"features\")\n",
    "\n",
    "#create the trainer\n",
    "nb = NaiveBayes(smoothing=3.0,modelType=\"multinomial\")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers+encoders+[catIndexer,assembler,nb])\n",
    "modelDF = pipeline.fit(trainingData)\n",
    "pr = modelDF.transform(testData)\n",
    "\n",
    "        \n",
    "#nb_model = nb.fit(trainingData)\n",
    "#predictions = nb_model.transform(testData)\n",
    "#predictions.select(\"Category\",\"label\",\"probability\",\"prediction\").show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.168234749295272"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Category: string (nullable = true)\n",
      " |-- DayofWeek: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- Hour: integer (nullable = true)\n",
      " |-- DayofWeek_index: double (nullable = false)\n",
      " |-- PdDistrict_index: double (nullable = false)\n",
      " |-- DayofWeek_index_encoded: vector (nullable = true)\n",
      " |-- PdDistrict_index_encoded: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----+--------+\n",
      "|prediction|         probability|label|Category|\n",
      "+----------+--------------------+-----+--------+\n",
      "|       0.0|[0.53448437557947...| 24.0|   ARSON|\n",
      "|       0.0|[0.24542309309522...| 24.0|   ARSON|\n",
      "|       0.0|[0.51895192873252...| 24.0|   ARSON|\n",
      "|       0.0|[0.42951776593071...| 24.0|   ARSON|\n",
      "|       0.0|[0.16712635744569...| 24.0|   ARSON|\n",
      "|       0.0|[0.24984065042701...| 24.0|   ARSON|\n",
      "|       0.0|[0.23482257786858...| 24.0|   ARSON|\n",
      "|       1.0|[0.14408813907401...| 24.0|   ARSON|\n",
      "|       0.0|[0.25634529121662...| 24.0|   ARSON|\n",
      "|       0.0|[0.39984210470407...| 24.0|   ARSON|\n",
      "|       0.0|[0.15056380399601...| 24.0|   ARSON|\n",
      "|       1.0|[0.07546281810829...| 24.0|   ARSON|\n",
      "|       0.0|[0.31182654883825...| 24.0|   ARSON|\n",
      "|       0.0|[0.19398871961872...|  3.0| ASSAULT|\n",
      "|       0.0|[0.31101393615506...|  3.0| ASSAULT|\n",
      "|       1.0|[0.14587969938541...|  3.0| ASSAULT|\n",
      "|       0.0|[0.23007237095400...|  3.0| ASSAULT|\n",
      "|       1.0|[0.14081335646053...|  3.0| ASSAULT|\n",
      "|       0.0|[0.25608338528047...|  3.0| ASSAULT|\n",
      "|       0.0|[0.23022881069107...|  3.0| ASSAULT|\n",
      "+----------+--------------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr.select(\"prediction\",\"probability\",\"label\",\"Category\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
